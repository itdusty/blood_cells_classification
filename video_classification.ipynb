{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchvideo.data import LabeledVideoDataset, make_clip_sampler, labeled_video_dataset\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    Permute\n",
    ")\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    Resize\n",
    ")\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo, \n",
    "    NormalizeVideo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_transforms = Compose([\n",
    "    ApplyTransformToKey(key='video',\n",
    "    transform=Compose([\n",
    "        UniformTemporalSubsample(20),\n",
    "        Normalize((0.45, 0.45, 0.45),(0.225, 0.225, 0.225)),\n",
    "        RandomShortSideScale(min_size=248, max_size=256),\n",
    "        CenterCropVideo(224),\n",
    "        RandomHorizontalFlip(p=0.5),\n",
    "    ]),\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:\\Projects\\ML\\Video classification\\youtube_action_naudio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"youtube_action_naudio\")\n",
    "folders = os.listdir()\n",
    "files_list = {\n",
    "    \"file\": [],\n",
    "    \"label\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, folder in enumerate(folders):\n",
    "    os.chdir(folder)\n",
    "    file_names = os.listdir()\n",
    "    files_list[\"file\"] += file_names\n",
    "    files_list[\"label\"] += [i for _ in range(len(file_names))]\n",
    "    os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_split = pd.DataFrame(files_list)\n",
    "df_for_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_split = df_for_split.sample(frac=1)\n",
    "ratio = 0.8\n",
    "train_size = int(df_for_split.shape[0] * ratio)\n",
    "train_data = df_for_split[0:train_size]\n",
    "test_data = df_for_split[train_size:]\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"youtube_action_naudio\")\n",
    "\n",
    "if not os.path.isdir(\"train\"):\n",
    "    os.mkdir(\"train\")\n",
    "    os.chdir(\"train\")\n",
    "    for folder in folders:\n",
    "        os.mkdir(folder)\n",
    "    os.chdir(\"..\")\n",
    "if not os.path.isdir(\"test\"):\n",
    "    os.mkdir(\"test\")\n",
    "    os.chdir(\"test\")\n",
    "    for folder in folders:\n",
    "        os.mkdir(folder)\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "inner_folder = \"\"\n",
    "for filename in train_data.file:\n",
    "    if \"shooting\" in filename:\n",
    "        inner_folder = \"basketball\"\n",
    "    elif \"biking\" in filename:\n",
    "        inner_folder = \"biking\"\n",
    "    elif \"diving\" in filename:\n",
    "        inner_folder = \"diving\"\n",
    "    elif \"golf\" in filename:\n",
    "        inner_folder = \"golf_swing\"\n",
    "    elif \"riding\" in filename:\n",
    "        inner_folder = \"horse_riding\"\n",
    "    elif \"juggle\" in filename:\n",
    "        inner_folder = \"soccer_juggling\"\n",
    "    elif \"swing\" in filename:\n",
    "        inner_folder = \"swing\"\n",
    "    elif \"tennis\" in filename:\n",
    "        inner_folder = \"tennis_swing\"\n",
    "    elif \"jumping\" in filename:\n",
    "        inner_folder = \"trampoline_jumping\"\n",
    "    elif \"spiking\" in filename:\n",
    "        inner_folder = \"volleyball_spiking\"\n",
    "    elif \"walk_dog\" in filename:\n",
    "        inner_folder = \"walking\"\n",
    "    os.chdir(inner_folder)\n",
    "    shutil.copyfile(filename, f\"../train/{inner_folder}/{filename}\")\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "for filename in test_data.file:\n",
    "    if \"shooting\" in filename:\n",
    "        inner_folder = \"basketball\"\n",
    "    elif \"biking\" in filename:\n",
    "        inner_folder = \"biking\"\n",
    "    elif \"diving\" in filename:\n",
    "        inner_folder = \"diving\"\n",
    "    elif \"golf\" in filename:\n",
    "        inner_folder = \"golf_swing\"\n",
    "    elif \"riding\" in filename:\n",
    "        inner_folder = \"horse_riding\"\n",
    "    elif \"juggle\" in filename:\n",
    "        inner_folder = \"soccer_juggling\"\n",
    "    elif \"swing\" in filename:\n",
    "        inner_folder = \"swing\"\n",
    "    elif \"tennis\" in filename:\n",
    "        inner_folder = \"tennis_swing\"\n",
    "    elif \"jumping\" in filename:\n",
    "        inner_folder = \"trampoline_jumping\"\n",
    "    elif \"spiking\" in filename:\n",
    "        inner_folder = \"volleyball_spiking\"\n",
    "    elif \"walk_dog\" in filename:\n",
    "        inner_folder = \"walking\"\n",
    "    os.chdir(inner_folder)\n",
    "    shutil.copyfile(filename, f\"../test/{inner_folder}/{filename}\")\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = labeled_video_dataset(f\"{dataset_path}/train/\", \n",
    "                                      clip_sampler=make_clip_sampler('random', 2),\n",
    "                                      transform=video_transforms, decode_audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.num_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import LightningModule, seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import classification_report\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        # model architecture\n",
    "        self.video_model = torch.hub.load(\"facebookresearch/pytorchvideo\", \"efficient_x3d_xs\", pretrained=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(400, 11)\n",
    "\n",
    "        self.lr = 1e-3\n",
    "        self.batch_size = 8\n",
    "        self.numworkers = 0\n",
    "        # evaluation metric\n",
    "        self.metric = torchmetrics.Accuracy(task='multiclass', num_classes=11)\n",
    "        # loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.video_model(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(params=self.parameters(), lr=self.lr)\n",
    "        scheduler = CosineAnnealingLR(opt, T_max=10, eta_min=1e-6, last_epoch=-1)\n",
    "        return {'optimizer': opt, 'lr_scheduler': scheduler}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = labeled_video_dataset(f\"{dataset_path}/train/\", \n",
    "                                      clip_sampler=make_clip_sampler('random', 2),\n",
    "                                      transform=video_transforms, decode_audio=False)\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.numworkers, pin_memory=True)\n",
    "        return loader\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        video, label = batch['video'], batch['label']\n",
    "        out = self.forward(video)\n",
    "        loss = self.criterion(out, label)\n",
    "        metric = self.metric(out, label.to(torch.int64))\n",
    "        return {'loss': loss, 'metric': metric}\n",
    "    \n",
    "    def on_train_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().numpy().round(2)\n",
    "        metric = torch.stack([x['metric'] for x in outputs]).mean().numpy().round(2)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_metric', metric)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        dataset = labeled_video_dataset(f\"{dataset_path}/test/\", \n",
    "                                      clip_sampler=make_clip_sampler('random', 2),\n",
    "                                      transform=video_transforms, decode_audio=False)\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.numworkers, pin_memory=True)\n",
    "        return loader\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        video, label = batch['video'], batch['label']\n",
    "        out = self.forward(video)\n",
    "        loss = self.criterion(out, label)\n",
    "        metric = self.metric(out, label.to(torch.int64))\n",
    "        return {'loss': loss, 'metric': metric}\n",
    "    \n",
    "    def on_validation_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().numpy().round(2)\n",
    "        metric = torch.stack([x['metric'] for x in outputs]).mean().numpy().round(2)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_metric', metric)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = labeled_video_dataset(f\"{dataset_path}/test/\", \n",
    "                                      clip_sampler=make_clip_sampler('random', 2),\n",
    "                                      transform=video_transforms, decode_audio=False)\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.numworkers, pin_memory=True)\n",
    "        return loader\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        video, label = batch['video'], batch['label']\n",
    "        out = self.forward(video)\n",
    "        return {'label': label, 'pred': out}\n",
    "    \n",
    "    def on_test_epoch_end(self, outputs):\n",
    "        label = torch.cat([x['label'] for x in outputs]).numpy()\n",
    "        pred = torch.cat([x['pred'] for x in outputs]).numpy()\n",
    "        print(classification_report(label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", dirpath=\"checkpoints\", filename=\"file\", save_last=True)\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel()\n",
    "seed_everything(0)\n",
    "trainer = Trainer(max_epochs=1,\n",
    "                  precision=16,\n",
    "                  accumulate_grad_batches=2,\n",
    "                  enable_progress_bar=True,\n",
    "                  num_sanity_val_steps=0,\n",
    "                  callbacks=[lr_monitor, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
