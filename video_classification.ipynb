{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itdusty/blood_cells_classification/blob/custom_dataset/video_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHKaApd7yxuZ"
      },
      "source": [
        "### Data preparations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVNkRk8-zBug",
        "outputId": "81fa386c-4944-4f0a-dcd0-75a50c07650f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6WJsfm8yzBZ",
        "outputId": "5bb696d5-af9e-4c77-d57a-e3dc6304c239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.0.9-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (3.1.2)\n",
            "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Collecting arrow<3.0,>=1.2.0 (from lightning)\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff<4.0,>=2.2.1 (from lightning)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.11.2)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (8.1.7)\n",
            "Collecting croniter<1.5.0,>=1.3.0 (from lightning)\n",
            "  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting dateutils<2.0 (from lightning)\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting deepdiff<8.0,>=5.7.0 (from lightning)\n",
            "  Downloading deepdiff-6.5.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<2.0,>=0.92.0 (from lightning)\n",
            "  Downloading fastapi-0.103.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n",
            "Collecting inquirer<5.0,>=2.10.0 (from lightning)\n",
            "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
            "Collecting lightning-cloud>=0.5.38 (from lightning)\n",
            "  Downloading lightning_cloud-0.5.38-py3-none-any.whl (659 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.0/660.0 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities<2.0,>=0.7.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning) (23.1)\n",
            "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.9.5)\n",
            "Requirement already satisfied: pydantic<2.2.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.10.12)\n",
            "Collecting python-multipart<2.0,>=0.0.5 (from lightning)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.31.0)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (13.5.2)\n",
            "Collecting starlette (from lightning)\n",
            "  Downloading starlette-0.31.1-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starsessions<2.0,>=1.2.1 (from lightning)\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch<4.0,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.1+cu118)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.1)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.5.0)\n",
            "Requirement already satisfied: urllib3<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.4)\n",
            "Collecting uvicorn<2.0 (from lightning)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.6.2)\n",
            "Collecting websockets<13.0 (from lightning)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.0.9-py3-none-any.whl (727 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning) (2023.3.post1)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi<2.0,>=0.92.0->lightning) (3.7.1)\n",
            "Collecting starlette (from lightning)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec<2025.0,>=2022.5.0->lightning) (3.8.5)\n",
            "Collecting blessed>=1.19.0 (from inquirer<5.0,>=2.10.0->lightning)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning)\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning)\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning) (2.1.3)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud>=0.5.38->lightning) (2.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.38->lightning) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (2.16.1)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (16.0.6)\n",
            "Collecting h11>=0.8 (from uvicorn<2.0->lightning)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi<2.0,>=0.92.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi<2.0,>=0.92.0->lightning) (1.1.3)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\n",
            "Installing collected packages: python-editor, websockets, readchar, python-multipart, ordered-set, lightning-utilities, h11, blessed, backoff, uvicorn, starlette, inquirer, deepdiff, dateutils, croniter, arrow, starsessions, fastapi, lightning-cloud, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed arrow-1.2.3 backoff-2.2.1 blessed-1.20.0 croniter-1.4.1 dateutils-0.6.12 deepdiff-6.5.0 fastapi-0.103.1 h11-0.14.0 inquirer-3.1.3 lightning-2.0.9 lightning-cloud-0.5.38 lightning-utilities-0.9.0 ordered-set-4.1.0 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.9 readchar-4.0.5 starlette-0.27.0 starsessions-1.3.0 torchmetrics-1.2.0 uvicorn-0.23.2 websockets-11.0.3\n",
            "Collecting pytorchvideo\n",
            "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fvcore (from pytorchvideo)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av (from pytorchvideo)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parameterized (from pytorchvideo)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting iopath (from pytorchvideo)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (1.23.5)\n",
            "Collecting yacs>=0.1.6 (from fvcore->pytorchvideo)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (4.66.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (2.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorchvideo) (4.5.0)\n",
            "Collecting portalocker (from iopath->pytorchvideo)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188685 sha256=05ef56ba57d72fc8c444ca6ea522947f8cd3defe88df66fc8d5c1fcf0868c0ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/4e/81/0f72a543be9ed7eb737c95bfc5da4025e73226b44368074ece\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=207db40b6a58a9dc7c8851342555a76573461bf104f768a90992bb06c864a89a\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31530 sha256=8f8f6fb4a721f6c79a771c88399d1847eda1f706f0c926b85a40c3da389f492c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built pytorchvideo fvcore iopath\n",
            "Installing collected packages: av, yacs, portalocker, parameterized, iopath, fvcore, pytorchvideo\n",
            "Successfully installed av-10.0.0 fvcore-0.1.5.post20221221 iopath-0.1.10 parameterized-0.9.0 portalocker-2.8.2 pytorchvideo-0.1.5 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install lightning\n",
        "!pip install pytorchvideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04mrmwwoyxub",
        "outputId": "90f86b8f-2d36-4dda-f658-6e2f5cfcb266"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from pytorchvideo.data import LabeledVideoDataset, make_clip_sampler, labeled_video_dataset\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    Normalize,\n",
        "    RandomShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    Permute\n",
        ")\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Lambda,\n",
        "    RandomCrop,\n",
        "    RandomHorizontalFlip,\n",
        "    Resize\n",
        ")\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvTfp6DMyxud"
      },
      "outputs": [],
      "source": [
        "video_transforms = Compose([\n",
        "    ApplyTransformToKey(key='video',\n",
        "    transform=Compose([\n",
        "        UniformTemporalSubsample(20),\n",
        "        Normalize((0.45, 0.45, 0.45),(0.225, 0.225, 0.225)),\n",
        "        # RandomShortSideScale(min_size=248, max_size=256),\n",
        "        # CenterCropVideo(224),\n",
        "        RandomHorizontalFlip(p=0.5),\n",
        "    ]),\n",
        "    ),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdtlJS6yyxue"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tA1no3Ryxue"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qubRA-qDdC3r"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Cells classification/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7TgA0_oAgGu"
      },
      "outputs": [],
      "source": [
        "os.chdir(dataset_path)\n",
        "os.chdir(\"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD43cH8J_tX4",
        "outputId": "1cb1e936-e068-4cf1-a511-f23ad07767ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(          files  erythrocytes  lymphocytes  high_erythrocytes  \\\n",
              " 9     traffic10            19           12                  1   \n",
              " 270  traffic271             6           20                  0   \n",
              " 888  traffic889             6            1                  0   \n",
              " 429  traffic430             3           14                  0   \n",
              " 296  traffic297             9            9                  0   \n",
              " ..          ...           ...          ...                ...   \n",
              " 992  traffic993             1            8                  0   \n",
              " 821  traffic822             0            1                  0   \n",
              " 882  traffic883            10            8                  0   \n",
              " 418  traffic419            14           11                  1   \n",
              " 0      traffic1             6            9                  0   \n",
              " \n",
              "      high_lymphocytes  blur  noise  \n",
              " 9                   1     0      0  \n",
              " 270                 1     0      0  \n",
              " 888                 0     0      0  \n",
              " 429                 1     0      0  \n",
              " 296                 0     0      0  \n",
              " ..                ...   ...    ...  \n",
              " 992                 0     0      0  \n",
              " 821                 0     0      0  \n",
              " 882                 0     0      0  \n",
              " 418                 1     0      0  \n",
              " 0                   0     0      0  \n",
              " \n",
              " [800 rows x 7 columns],\n",
              "            files  erythrocytes  lymphocytes  high_erythrocytes  \\\n",
              " 409   traffic410             8           19                  0   \n",
              " 750   traffic751             2            1                  0   \n",
              " 237   traffic238             8           10                  0   \n",
              " 374   traffic375            13           19                  1   \n",
              " 606   traffic607            15            2                  1   \n",
              " ..           ...           ...          ...                ...   \n",
              " 918   traffic919             9           13                  0   \n",
              " 243   traffic244            12           11                  1   \n",
              " 999  traffic1000            18            7                  1   \n",
              " 822   traffic823             9           13                  0   \n",
              " 307   traffic308             4           13                  0   \n",
              " \n",
              "      high_lymphocytes  blur  noise  \n",
              " 409                 1     0      0  \n",
              " 750                 0     0      0  \n",
              " 237                 0     0      0  \n",
              " 374                 1     0      0  \n",
              " 606                 0     0      0  \n",
              " ..                ...   ...    ...  \n",
              " 918                 1     0      0  \n",
              " 243                 1     0      0  \n",
              " 999                 0     0      0  \n",
              " 822                 1     0      0  \n",
              " 307                 1     0      0  \n",
              " \n",
              " [200 rows x 7 columns])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe = pd.read_csv(\"DataFrame.csv\", index_col=0)\n",
        "dataframe = dataframe.sample(frac=1)\n",
        "ratio = 0.8\n",
        "train_size = int(dataframe.shape[0] * ratio)\n",
        "train_data = dataframe[0:train_size]\n",
        "test_data = dataframe[train_size:]\n",
        "train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm40twbHybAo"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(LabeledVideoDataset):\n",
        "    def __init__(self, dataset_path, dataframe, target_name, transforms, clip_sampler_type='random', clip_duration=1):\n",
        "      df = dataframe.reset_index()\n",
        "      paths = []\n",
        "      for i, file_name in enumerate(df['files']):\n",
        "          temp_dict = df.iloc[i].to_dict()\n",
        "          temp_dict['label'] = df[target_name][i]\n",
        "          temp_dict.pop(target_name)\n",
        "          temp_dict.pop('files')\n",
        "          temp_dict.pop('index')\n",
        "          paths.append((f\"{dataset_path}/{file_name}\", temp_dict))\n",
        "      super().__init__(labeled_video_paths=paths,\n",
        "                       clip_sampler=make_clip_sampler(clip_sampler_type, clip_duration),\n",
        "                       transform=transforms, decode_audio=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IevznUsNmnk2"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(dataset_path=dataset_path, dataframe=train_data,\n",
        "                              target_name='high_erythrocytes',\n",
        "                              transforms=video_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V65RGWKeyxui",
        "outputId": "53493a3c-9143-4fab-9206-5f7c88068e94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.num_videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgbT8X8Tyxui"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To_8-yuoyxui"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorch_lightning import LightningModule, seed_everything, Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.metrics import classification_report\n",
        "import torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEILRhilyxuj"
      },
      "outputs": [],
      "source": [
        "class TestModel(LightningModule):\n",
        "    def __init__(self, target_label, num_classes=2):\n",
        "        super(TestModel, self).__init__()\n",
        "        # model architecture\n",
        "        self.video_model = torch.hub.load(\"facebookresearch/pytorchvideo\", \"efficient_x3d_xs\", pretrained=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear = nn.Linear(400, num_classes)\n",
        "\n",
        "        self.lr = 1e-3\n",
        "        self.batch_size = 8\n",
        "        self.numworkers = 0\n",
        "        # evaluation metric\n",
        "        self.metric = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
        "        # loss function\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        # helpers\n",
        "        self.target_label = target_label\n",
        "        self.training_step_outputs = []\n",
        "        self.validation_step_outputs = []\n",
        "        self.testing_step_outputs = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.video_model(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = torch.optim.AdamW(params=self.parameters(), lr=self.lr)\n",
        "        scheduler = CosineAnnealingLR(opt, T_max=10, eta_min=1e-6, last_epoch=-1)\n",
        "        return {'optimizer': opt, 'lr_scheduler': scheduler}\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        dataset = CustomDataset(dataset_path=dataset_path, dataframe=train_data,\n",
        "                              target_name=self.target_label,\n",
        "                              transforms=video_transforms)\n",
        "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.numworkers, pin_memory=True)\n",
        "        return loader\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        video, label = batch['video'], batch['label']\n",
        "        out = self.forward(video)\n",
        "        loss = self.criterion(out, label)\n",
        "        metric = self.metric(out, label.to(torch.int64))\n",
        "        self.training_step_outputs.append({'loss': loss, 'metric': metric})\n",
        "        print({'loss': loss, 'metric': metric})\n",
        "        return {'loss': loss, 'metric': metric}\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        outputs = self.training_step_outputs\n",
        "        loss = torch.stack([x['loss'] for x in outputs]).mean().cpu().detach().numpy().round(2)\n",
        "        metric = torch.stack([x['metric'] for x in outputs]).mean().cpu().detach().numpy().round(2)\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_metric', metric)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        dataset = CustomDataset(dataset_path=dataset_path, dataframe=test_data,\n",
        "                              target_name=self.target_label,\n",
        "                              transforms=video_transforms)\n",
        "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.numworkers, pin_memory=True)\n",
        "        return loader\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        video, label = batch['video'], batch['label']\n",
        "        out = self.forward(video)\n",
        "        loss = self.criterion(out, label)\n",
        "        metric = self.metric(out, label.to(torch.int64))\n",
        "        self.validation_step_outputs.append({'loss': loss, 'metric': metric})\n",
        "        return {'loss': loss, 'metric': metric}\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        outputs = self.validation_step_outputs\n",
        "        loss = torch.stack([x['loss'] for x in outputs]).mean().cpu().detach().numpy().round(2)\n",
        "        metric = torch.stack([x['metric'] for x in outputs]).mean().cpu().detach().numpy().round(2)\n",
        "        self.log('val_loss', loss)\n",
        "        self.log('val_metric', metric)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        dataset = CustomDataset(dataset_path=dataset_path, dataframe=test_data,\n",
        "                              target_name=self.target_label,\n",
        "                              transforms=video_transforms)\n",
        "        loader = DataLoader(dataset, batch_size=self.batch_size, num_workers=self.numworkers, pin_memory=True)\n",
        "        return loader\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        video, label = batch['video'], batch['label']\n",
        "        out = self.forward(video)\n",
        "        self.testing_step_outputs.append({'label': label, 'pred': out})\n",
        "        return {'label': label, 'pred': out}\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        outputs = self.testing_step_outputs\n",
        "        label = torch.cat([x['label'] for x in outputs]).cpu().detach().numpy()\n",
        "        pred = torch.cat([x['pred'].argmax(dim=1) for x in outputs]).cpu().detach().numpy()\n",
        "        print(classification_report(label, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn5Dp3rOyxuj"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", dirpath=\"checkpoints\", filename=\"file\", save_last=True)\n",
        "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDS3zCEpyxuj",
        "outputId": "c7f8f050-1b70-4dde-c58a-b302ecc46588"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n",
            "/usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:554: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "  rank_zero_warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "model = TestModel(num_classes=2, target_label='high_erythrocytes')\n",
        "seed_everything(0)\n",
        "trainer = Trainer(max_epochs=1,\n",
        "                  precision=16,\n",
        "                  accumulate_grad_batches=2,\n",
        "                  enable_progress_bar=True,\n",
        "                  num_sanity_val_steps=0,\n",
        "                  callbacks=[lr_monitor, checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e2440059aac74231928565f523fced3f",
            "cd33146adc714452bfa30c7683d957ff",
            "d5a1340afc4a477685fc8b356563da9e",
            "ac47bf5ef55f4b4c97f1094ce8893c10",
            "e7fd115b768c43d7ba31312d1c0541b3",
            "0477b15935ee43a98c085a4d819209c8",
            "370d4574bd4644cda2d089fea61ebf62",
            "4ee00bd552834f52a59b8c61a59b153a",
            "26ed4533e8874ffe8a99fc26cfe1a968",
            "df8fa2305a0a4dcb8276dc9c0bec57e3",
            "422befc9c27a493fb6f9e8256d11e6c9"
          ]
        },
        "id": "jj38VVixyxuk",
        "outputId": "4eb51590-f0c3-45af-9fb1-c2d9d772f182"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Cells classification/checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name        | Type               | Params\n",
            "---------------------------------------------------\n",
            "0 | video_model | EfficientX3d       | 3.8 M \n",
            "1 | relu        | ReLU               | 0     \n",
            "2 | linear      | Linear             | 802   \n",
            "3 | metric      | MulticlassAccuracy | 0     \n",
            "4 | criterion   | CrossEntropyLoss   | 0     \n",
            "---------------------------------------------------\n",
            "3.8 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.8 M     Total params\n",
            "15.180    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2440059aac74231928565f523fced3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': tensor(0.5942, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.6544, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.3750, device='cuda:0')}\n",
            "{'loss': tensor(0.7545, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.5797, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.6727, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.4833, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.8590, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.5000, device='cuda:0')}\n",
            "{'loss': tensor(0.5689, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.4638, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(1.1891, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.3750, device='cuda:0')}\n",
            "{'loss': tensor(0.2502, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.4223, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.3290, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.6373, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.2959, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.4580, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.1577, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.7154, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.2744, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(1.3091, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.5000, device='cuda:0')}\n",
            "{'loss': tensor(0.1060, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.1876, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.8950, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.1671, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.5778, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.6417, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.1602, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.4087, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.2559, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(1.1139, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.7578, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(1.6178, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.5000, device='cuda:0')}\n",
            "{'loss': tensor(0.6079, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(2.1531, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.1685, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.1075, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.3932, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.3292, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.1473, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.6803, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(1.1810, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.1578, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.6981, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.0837, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.5678, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(1.0253, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.5000, device='cuda:0')}\n",
            "{'loss': tensor(0.1678, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.7390, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.2443, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.5997, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.2984, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.1243, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.3259, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.5995, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.7500, device='cuda:0')}\n",
            "{'loss': tensor(0.5023, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(1.0327, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.2202, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.7234, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.6250, device='cuda:0')}\n",
            "{'loss': tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(1., device='cuda:0')}\n",
            "{'loss': tensor(0.6113, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n",
            "{'loss': tensor(0.8371, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.5000, device='cuda:0')}\n",
            "{'loss': tensor(0.7832, device='cuda:0', grad_fn=<NllLossBackward0>), 'metric': tensor(0.8750, device='cuda:0')}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 243, in fetch_image\n",
            "    img_str = np.frombuffer(f.read(), np.uint8)\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 190, in advance\n",
            "    batch = next(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\", line 120, in __next__\n",
            "    self.batches.append(super().__next__())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\", line 58, in __next__\n",
            "    batch = next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 285, in __next__\n",
            "    out = next(self._iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 65, in __next__\n",
            "    out[i] = next(self.iterators[i])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
            "    data.append(next(self.dataset_iter))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/labeled_video_dataset.py\", line 183, in __next__\n",
            "    self._loaded_clip = video.get_clip(clip_start, clip_end)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 206, in get_clip\n",
            "    clip_frames = _load_images_with_retries(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 253, in _load_images_with_retries\n",
            "    optional_threaded_foreach(fetch_image, enumerate(image_paths), multithreaded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/utils.py\", line 138, in optional_threaded_foreach\n",
            "    target(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 242, in fetch_image\n",
            "    with g_pathmgr.open(image_path, \"rb\") as f:\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-40-45d4afebefac>\", line 1, in <cell line: 1>\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 66, in _call_and_handle_interrupt\n",
            "    logger.finalize(\"failed\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\", line 32, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 228, in finalize\n",
            "    super().finalize(status)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\", line 32, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/loggers/tensorboard.py\", line 290, in finalize\n",
            "    self.experiment.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 1207, in close\n",
            "    writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 156, in close\n",
            "    self.event_writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 134, in close\n",
            "    self._async_writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 204, in close\n",
            "    self._writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/record_writer.py\", line 46, in close\n",
            "    self._writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 241, in close\n",
            "    self._writable_file.close()\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/drive/MyDrive/Cells classification/lightning_logs/version_17/events.out.tfevents.1695561508.f5af515e2649.176.7; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 243, in fetch_image\n",
            "    img_str = np.frombuffer(f.read(), np.uint8)\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 190, in advance\n",
            "    batch = next(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\", line 120, in __next__\n",
            "    self.batches.append(super().__next__())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\", line 58, in __next__\n",
            "    batch = next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 285, in __next__\n",
            "    out = next(self._iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 65, in __next__\n",
            "    out[i] = next(self.iterators[i])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
            "    data.append(next(self.dataset_iter))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/labeled_video_dataset.py\", line 183, in __next__\n",
            "    self._loaded_clip = video.get_clip(clip_start, clip_end)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 206, in get_clip\n",
            "    clip_frames = _load_images_with_retries(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 253, in _load_images_with_retries\n",
            "    optional_threaded_foreach(fetch_image, enumerate(image_paths), multithreaded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/utils.py\", line 138, in optional_threaded_foreach\n",
            "    target(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 242, in fetch_image\n",
            "    with g_pathmgr.open(image_path, \"rb\") as f:\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-40-45d4afebefac>\", line 1, in <cell line: 1>\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 66, in _call_and_handle_interrupt\n",
            "    logger.finalize(\"failed\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\", line 32, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 228, in finalize\n",
            "    super().finalize(status)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\", line 32, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/loggers/tensorboard.py\", line 290, in finalize\n",
            "    self.experiment.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 1207, in close\n",
            "    writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 156, in close\n",
            "    self.event_writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 134, in close\n",
            "    self._async_writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 204, in close\n",
            "    self._writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/record_writer.py\", line 46, in close\n",
            "    self._writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 241, in close\n",
            "    self._writable_file.close()\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/drive/MyDrive/Cells classification/lightning_logs/version_17/events.out.tfevents.1695561508.f5af515e2649.176.7; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 243, in fetch_image\n",
            "    img_str = np.frombuffer(f.read(), np.uint8)\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 190, in advance\n",
            "    batch = next(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\", line 120, in __next__\n",
            "    self.batches.append(super().__next__())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\", line 58, in __next__\n",
            "    batch = next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 285, in __next__\n",
            "    out = next(self._iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 65, in __next__\n",
            "    out[i] = next(self.iterators[i])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
            "    data.append(next(self.dataset_iter))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/labeled_video_dataset.py\", line 183, in __next__\n",
            "    self._loaded_clip = video.get_clip(clip_start, clip_end)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 206, in get_clip\n",
            "    clip_frames = _load_images_with_retries(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 253, in _load_images_with_retries\n",
            "    optional_threaded_foreach(fetch_image, enumerate(image_paths), multithreaded)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/utils.py\", line 138, in optional_threaded_foreach\n",
            "    target(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/frame_video.py\", line 242, in fetch_image\n",
            "    with g_pathmgr.open(image_path, \"rb\") as f:\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-40-45d4afebefac>\", line 1, in <cell line: 1>\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 66, in _call_and_handle_interrupt\n",
            "    logger.finalize(\"failed\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\", line 32, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/tensorboard.py\", line 228, in finalize\n",
            "    super().finalize(status)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\", line 32, in wrapped_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/loggers/tensorboard.py\", line 290, in finalize\n",
            "    self.experiment.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 1207, in close\n",
            "    writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 156, in close\n",
            "    self.event_writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 134, in close\n",
            "    self._async_writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 204, in close\n",
            "    self._writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/record_writer.py\", line 46, in close\n",
            "    self._writer.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\", line 241, in close\n",
            "    self._writable_file.close()\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/drive/MyDrive/Cells classification/lightning_logs/version_17/events.out.tfevents.1695561508.f5af515e2649.176.7; Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21U0bYumlkH_"
      },
      "outputs": [],
      "source": [
        "trainer.validate(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR99tqb2lyR1"
      },
      "outputs": [],
      "source": [
        "trainer.test(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVJa3NErmkHN"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0477b15935ee43a98c085a4d819209c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ed4533e8874ffe8a99fc26cfe1a968": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "370d4574bd4644cda2d089fea61ebf62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422befc9c27a493fb6f9e8256d11e6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ee00bd552834f52a59b8c61a59b153a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac47bf5ef55f4b4c97f1094ce8893c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df8fa2305a0a4dcb8276dc9c0bec57e3",
            "placeholder": "​",
            "style": "IPY_MODEL_422befc9c27a493fb6f9e8256d11e6c9",
            "value": " 60/? [3:21:47&lt;00:00, 201.80s/it, v_num=17]"
          }
        },
        "cd33146adc714452bfa30c7683d957ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0477b15935ee43a98c085a4d819209c8",
            "placeholder": "​",
            "style": "IPY_MODEL_370d4574bd4644cda2d089fea61ebf62",
            "value": "Epoch 0: "
          }
        },
        "d5a1340afc4a477685fc8b356563da9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee00bd552834f52a59b8c61a59b153a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26ed4533e8874ffe8a99fc26cfe1a968",
            "value": 1
          }
        },
        "df8fa2305a0a4dcb8276dc9c0bec57e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2440059aac74231928565f523fced3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd33146adc714452bfa30c7683d957ff",
              "IPY_MODEL_d5a1340afc4a477685fc8b356563da9e",
              "IPY_MODEL_ac47bf5ef55f4b4c97f1094ce8893c10"
            ],
            "layout": "IPY_MODEL_e7fd115b768c43d7ba31312d1c0541b3"
          }
        },
        "e7fd115b768c43d7ba31312d1c0541b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}